---
title: "Modelando probabilidades"
author: "Sebastian Castillo"
date: '2022-05-29'
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require("data.table")
library(purrr)
library(dplyr)
library(stringr)
library(kableExtra)
options(scipen = 999) # inhabilito notacion científica
```


***"To err is human, to forgive divine, but to include errors in your design is statistical"***, Leslie Kish.       


```{r}
  ftirar  <- function( prob, qty )
  {
    return( sum( runif(qty) < prob ) )
  }

  mejor      <-  0.7
  peloton    <-  ( 501:599 ) / 1000
  jugadores  <-  c( peloton, mejor ) 
  ids_juegan  <- 1:100   
  
```

# Problema de Cazatalentos

## Veamos la probabilidad de tiros errados (fracasos) en algunos jugadores

Supongamos que hacemos tirar a algunos jugadores del grupo analizado: ¿cuál es la probabilidad que tienen, por ejemplo, el mejor (indice de enceste 0.7) y el segundo mejor (indice de enceste 0.599) de fallar siempre dado n tiros?

```{r}
tiros = 1:15
prob = vector()
jugador_id = 1 - jugadores[100]
for (i in 1:length(tiros)){
  prob[[i]] = jugador_id ^ tiros[i]
}

tibble(tiros, prob) %>% kable()

```

```{r}
tiros = 1:15
prob = vector()
jugador_id = 1 - jugadores[99]
for (i in 1:length(tiros)){
  prob[[i]] = jugador_id ^ tiros[i]
}
tibble(tiros, prob) %>% kable()

```

La variable tiros sigue una distribución Bernoulli ( distribución de probabilidad discreta, dónde el valor1 (éxito) ocurre con la probabilidad p y el valor 0 (fracaso) con la probabilidad q=1-p). En este caso la distribución tiene como parámetro p='indice de enceste' de cada jugador, de acuerdo con los datos iniciales del problema. Los tiros de los jugadores y sus resultados (enceste o no_enceste) constituyen ensayos independientes, de tal forma que los resultados de los encestes de un jugador sigue una distribución binomial de parámetros *N* e *'indice de enceste'*.      

Dado estas características, y por los ensayos efectuados no puede reconstruirse a posteriori la probabilidad subyacente a una distribución pues, aunque en los experimentos estmos empleando el índice de enceste para generar éxitos y fracasos, el patrón resultante es aleatorio.    

## Experimentos de fracasos sucesivos en el mejor jugador

Segun lo visto la probabilidad que el mejor jugador falle 4 tiros seguidos es de 0.008, mientras que la probabilidad que falle el segundo mejor es de 0.025, mucho mayor. Podemos utilizar la ventana de 4 tiros errados para eliminar jugadores.

```{r}

resultados  <- data.table("id" = ids_juegan)

for(j in 1:139){
  
   result  <- data.table("id" = ids_juegan)
  
  for(i in 2:6){
    result[[i]] = mapply( ftirar, jugadores, 1)
  }
  
  resultados = bind_rows(resultados, result)
  
}
```


```{r}
resultados = resultados %>% 
  filter(!is.na(V2)) 
```

```{r}
ids_resumen = resultados$id
encestes = resultados %>% select(-id) %>% rowSums()
resumen = tibble(ids_resumen, encestes)  

```

```{r}
probabilidades_encestes = resumen %>% 
  group_by(ids_resumen, encestes, .drop=FALSE) %>% 
  summarise(cantidad = n()) %>% 
  group_by(ids_resumen) %>% 
  mutate(total_tiros = sum(cantidad)) %>% rowwise() %>% 
  mutate(propor = round(cantidad/total_tiros, digits = 5))
```

## Probabilidad del jugador 100 de fallar n tiros consecutivos meter 1/n, 2/n, 3/n... en mil intentos


```{r}
probabilidades_encestes[probabilidades_encestes$ids_resumen == 100, ]
```
## Probabilidad del jugador 99 de fallar n tiros consecutivos, meter 1/n, 2/n, 3/n... en mil intentos

Testeamos este jugador pues es el seguno con mejor índice de enceste.


```{r}
probabilidades_encestes[probabilidades_encestes$ids_resumen == 99, ]
```

## Conclusión provisoria (en vista a la construcción de un algoritmo de búsqueda con accuracy del .99% )

En las anteriores tablas vemos que mientras que la probabilidad del jugador 100 de errar 4 tiros consecutivos es de 0.005, la del jugador 99 es mucho mayor (más probable) de 0.030.    

Creo que por acá hay una diferencia sistemática para armar un algoritmo de búsqueda.

O quiezar tomar el vector resultante de cantidad tota de fallos consecutivas 0/n, 1/n, 2/n, e identificar el jugador con menos cantidades de fallas, o suma de las tres proporciones con mayor fallas.


## Viendo las posibilidad de tiros fallados en el mejor jugador

Errar 11 tiros tiene una probabilidad de 0.0000018, eso quiere decir que el mejor jugado tiene una posibilidad menor a 1% en 10.000 tiros. Experimentaremos sobre esto.

```{r}
# resultados  <- data.table("id" = 100)
# for(j in 1:10){
#   
#    result  <- data.table("id" = ids_juegan)
#   
#   for(i in 2:12){
#     result[[i]] = mapply( ftirar, jugadores[100], 1)
#   }
#   
#   resultados = bind_rows(resultados, result)
#   
# }
```


```{r}
# resultados = resultados %>% 
#   filter(!is.na(V2)) 
# 
# ids_resumen = resultados$id
# encestes = resultados %>% select(-id) %>% rowSums()
# resumen = tibble(ids_resumen, encestes)  

```

```{r}
# probabilidades_encestes = resumen %>% 
#   mutate(encestes = as.factor(encestes)) %>% 
#   group_by(ids_resumen, encestes, .drop=FALSE) %>% 
#   summarise(cantidad = n()) %>% 
#   group_by(ids_resumen) %>% 
#   mutate(total_tiros = sum(cantidad)) %>% rowwise() %>% 
#   mutate(propor = round(cantidad/total_tiros, digits = 5))
```


```{r}
probabilidades_encestes[probabilidades_encestes$ids_resumen == 100, ]
```

## Optimizacion

Tengo que generar todos los experimentos de tiros que sean posibles para hacer que el mejor jugado converga hacia su ìndice de enceste para lo cual debe desacerme de los malos jugadores. 

## Reconocer la probabilidad teórica de 0.7 con 415 tiros? Porqué?

Números de tiros (experimentos) donde convergen la probabilidad teórica (a priori) con la probabilidad empírica (a posterior): como se deteriman? Cual es la función?

```{r}
resultado_tiro = vector()
tiro_numero = vector()

set.seed(12346)
iteraciones = 800

for(i in 1:iteraciones){
  tiro_numero[[i]] = i
  resultado_tiro[[i]] = mapply(ftirar, jugadores[100], 1)
}

df = tibble(tiro_numero, resultado_tiro) %>% 
 mutate(cumsum = cumsum(resultado_tiro)) %>% 
  rowwise() %>% mutate(crecimiento = cumsum/tiro_numero)


df %>% filter(tiro_numero > 1) %>% 
  ggplot(aes(x=tiro_numero, y=crecimiento)) +
  geom_line() +
  geom_hline(yintercept=0.7, color = "red", linetype="dashed") +
  labs(title = str_c("Reconociendo probabilidad teórica. Ultimo score: ",df$crecimiento[iteraciones], '.'))
  
```

### Elemento de optimizaciòn

Optimizar tiros: para optimizar tiros se necesitan eliminar jugadores. Para eso se necesita un criterio de eliminación: cantidad de aciertos (obvio). Se tiene que adoptar un criterio estricto como eliminar más pero no tan dura como para eliminar al mejor a medida que este suma experimentos y converge a su probabilidad teórica.  

El criterio de eliminaciòn es le desviaciòn estaàndar en la distribuciòn binomial.  A los 50 tiros si hay un jugado que està por debajo de la **3 desviación estandar** para los 50 tiros (en esta distribuviòn binomial) no es el mejor, se fue.

Suma de probabilidad de todos los jugadores. 


